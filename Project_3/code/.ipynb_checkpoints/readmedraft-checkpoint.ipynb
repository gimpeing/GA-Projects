{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png)\n",
    "\n",
    "# Project 3: Web APIs & Classification\n",
    "\n",
    "## Context and Problem Statement\n",
    "Product review is widely available in this digital world. People tends to do research on product reviews prior to purchase. However, there is fake review which is written by professional to boost the sale of a particular product. Thus, how can we differentiate true user's genuine review from fake review?\n",
    "\n",
    "We can use Natural Language Processing (NLP) to train a classifier to best predict or differentiate the two.\n",
    "\n",
    "To do this, content from two subreddits were collected to practice the various models work on this binary classification problem.\n",
    "Subreddits selected are:\n",
    "1. [nosleep](https://www.reddit.com/r/nosleep/)\n",
    "2. [Thetruthishere](https://www.reddit.com/r/Thetruthishere/)\n",
    "\n",
    "The two subreddits are about horror 'story'. Content in `nosleep` is of made up horror stories , whereas `Thetruthishere` is true horror personal experience.\n",
    "\n",
    "Once the model is able to classify and distinguish between these two subreddits, then it would be able to use similar approach to detect made up (fake) review of a product. \n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "### Contents\n",
    "\n",
    "- [Data Collection](#Data-Collection)\n",
    "- [Data Cleaning and Exploratory Data Analysis (EDA)](#Data-Cleaning-and-Exploratory-Data-Analysis-(EDA))\n",
    "- [Preprocessing](#Preprocessing)\n",
    "- [Modelling](#Modelling)\n",
    "- [Model Evaluation](#Model-Evaluation)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)\n",
    "- [Sources](#Sources)\n",
    "\n",
    "\n",
    "### Data Collection\n",
    "**Data Collection** is done by webscraping using the `requests` library. By default, Reddit give 25 posts per request. To get enough data, I'll need to use a `for loop` to continuously scrap the data by including `time.sleep()` function at the end of each loop to allow for a break in between requests.\n",
    "\n",
    "### Data Cleaning and Exploratory Data Analysis (EDA)\n",
    "Cleaning involved removing duplicate post, removing post with null content. This is left with 834 posts from `nosleep` and 937 posts from `Thetruthishere`. It was observed that `nosleep` has much longer post content comnpared to `Thetruthishere`. Asides, CountVectorizer is used to find out the most frequent words appeared in the two subreddits. In addition, I also count the number of words in each post content. It can be clearly seen from the histogram that `nosleep` has way much longer post length compared to `Thetruthishere`. This indicated that make-up story is always much more lengthy that the true personal experience.\n",
    "\n",
    "### Preprocessing\n",
    "Pre-processing includes using Regex to remove html links, punctuation, non-letters word, lemmatizing, and removing stopwords. `Subreddit` column that indicate which subreddit the post originated from is converted into binary number by assigning `1` to `nosleep` and `0` to `Thetruthishere`. The data was divided into train set (75%) and test set (25%).\n",
    "\n",
    "### Modelling\n",
    "Baseline score, which is the null model by predicting the majority class is defined.\n",
    "Baseline accuracy = *53%*\n",
    "\n",
    "|Target Variable|Normalized Counts|\n",
    "|---|---|\n",
    "|1|0.529678|\n",
    "|0|0.470322|\n",
    "\n",
    "*where 1 equals `nosleep`, 0 equals `Thetruthishere`*\n",
    "\n",
    "Two Vectorizer extraction techniques are used to transform the post's content (string of words) into numeric X matrix that is able to use for modeling are:\n",
    "- CountVectorizer\n",
    "- TfidfVectorizer\n",
    "\n",
    "For each Vectorizer, two classification models are built:\n",
    "- Multinomial Naive Bayes\n",
    "- Logistic Regression\n",
    "\n",
    "Model optimization was done by using GridSearchCV to identify the optimal hyperparameters and were built into the classificaiton models.\n",
    "\n",
    "### Model Evaluation\n",
    "Accuracy score was used to evaluate how well the classification model perform. This is because there is no greater detriment to false positive (actual post is `Thetruthishere` but predict it came from `nosleep`'s subreddit).\n",
    "Generally, all models perform well with accuracy in the range of 92%-94%. They all outperform the baseline. New post from each subreddit were pulled to check how well the model generalize to unseen data. *Logistic Regression model using TfidfVectorizer* performs the best as it is able to predict equally well by having consistent accuracy score around **93%**\n",
    "\n",
    "\n",
    "### Conclusions and Recommendations\n",
    "**Results summary:**\n",
    "\n",
    "|Classifier Model|Vectorizer|Test Accuracy|Unseen data Accuracy|Sensitivity|\n",
    "|---|---|---|---|---|\n",
    "|Logistic Regression|CountVectorizer|94.4%|92.7%|91.2%\n",
    "|Multinomial Naive Bayes|CountVectorizer|92.1%|82.7%|90.8%\n",
    "|Logistic Regression|TfidfVectorizer|**93.8%**|**93.3%**|91.6%\n",
    "|Multinomial Naive Bayes|TfidfVectorizer|93.0%|84.0%|92.0%\n",
    "\n",
    "**TfidfVectorizer + Logistic Regression** is the highest-performing model as apart from high accuracy score, it is able to generalize better to unseen data. However, other than Accuracy score, sensitivity is another important metric to evaluate the model if were to apply to identify fake review from true review.\n",
    "This is due to there is concern in type II error, that is the **False Negative**. FN means predict it is true review, but in actual case, it is a fake review. Thus, further tuning to improves sensitivity is important as it minimize the False Negative.\n",
    "\n",
    "### Sources\n",
    "1. [nosleep Subreddit](https://www.reddit.com/r/nosleep/)\n",
    "2. [Thetruthishere Subrreddit](https://www.reddit.com/r/Thetruthishere/)\n",
    "3. [video on how to use Reddit's API](https://www.youtube.com/watch?v=5Y3ZE26Ciuk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
