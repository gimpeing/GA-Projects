{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement\n",
    "\n",
    "For project 3, your goal is two-fold:\n",
    "\n",
    "Using Reddit's API, you'll collect posts from two subreddits of your choosing.\n",
    "You'll then use NLP to train a classifier on which subreddit a given post came from. This is a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "\n",
    "#To visualize the whole grid\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Explore which items to scrap from reddits.com\n",
    "\n",
    "The two subreddits to scare are:\n",
    "1. nosleep\n",
    "2. the true is here\n",
    "\n",
    "Using the `requests` library to gather the data, i.e. post from reddits.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### url for the first reddit sub-post:\n",
    "url = 'https://www.reddit.com/r/nosleep.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Reddit has throttled python's default user agent, I'll need to set a custom user-agent to get the requests to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### custom user-agent\n",
    "headers = {'User-agent': 'Pony Inc 1.0'}\n",
    "res = requests.get(url, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check the status, it returns 200, means it is okay\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use res.json() to convert the response into a dictionary format and set this to a variable\n",
    "nosleep_dict = res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial exploration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'kind']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st layer of dict: It has two keys, 'kind' & 'data'\n",
    "sorted(nosleep_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['after', 'before', 'children', 'dist', 'modhash']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd layer of dict, for key 'data', it has 5 keys.\n",
    "# 'children' & 'after' are the two keys that I would like to scrap\n",
    "sorted(nosleep_dict['data'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'kind']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd layer of dict, it has another two keys, 'kind' & 'data'\n",
    "# again, the 'data' has is the info that I will need\n",
    "sorted(nosleep_dict['data']['children'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>hidden</th>\n",
       "      <th>pwls</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>downs</th>\n",
       "      <th>hide_score</th>\n",
       "      <th>name</th>\n",
       "      <th>quarantine</th>\n",
       "      <th>link_flair_text_color</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>ups</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>is_reddit_media_domain</th>\n",
       "      <th>is_meta</th>\n",
       "      <th>category</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>can_mod_post</th>\n",
       "      <th>score</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>edited</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>gildings</th>\n",
       "      <th>content_categories</th>\n",
       "      <th>is_self</th>\n",
       "      <th>mod_note</th>\n",
       "      <th>created</th>\n",
       "      <th>link_flair_type</th>\n",
       "      <th>wls</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>domain</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>selftext_html</th>\n",
       "      <th>likes</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>view_count</th>\n",
       "      <th>archived</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>is_crosspostable</th>\n",
       "      <th>pinned</th>\n",
       "      <th>over_18</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>awarders</th>\n",
       "      <th>media_only</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>locked</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>visited</th>\n",
       "      <th>removed_by</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>mod_reason_by</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>link_flair_background_color</th>\n",
       "      <th>id</th>\n",
       "      <th>is_robot_indexable</th>\n",
       "      <th>report_reasons</th>\n",
       "      <th>author</th>\n",
       "      <th>discussion_type</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>contest_mode</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>permalink</th>\n",
       "      <th>parent_whitelist_status</th>\n",
       "      <th>stickied</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>nosleep</td>\n",
       "      <td></td>\n",
       "      <td>t2_c446v4f</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>February 2020 contest nominations</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/nosleep</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_fdub8s</td>\n",
       "      <td>False</td>\n",
       "      <td>dark</td>\n",
       "      <td>None</td>\n",
       "      <td>public</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>56</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[writing]</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1.583439e+09</td>\n",
       "      <td>text</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>redd.it</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'count': 1, 'is_enabled': True, 'subreddit_i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>moderator</td>\n",
       "      <td>t5_2rm4d</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>fdub8s</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>TheCusterWolf</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/nosleep/comments/fdub8s/february_2020_conte...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>True</td>\n",
       "      <td>https://redd.it/fduax3</td>\n",
       "      <td>13825083</td>\n",
       "      <td>1.583410e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>nosleep</td>\n",
       "      <td></td>\n",
       "      <td>t2_m297o</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>January 2020 Winners!</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/nosleep</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_fecu80</td>\n",
       "      <td>False</td>\n",
       "      <td>dark</td>\n",
       "      <td>None</td>\n",
       "      <td>public</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>[writing]</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1.583527e+09</td>\n",
       "      <td>text</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>redd.it</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>moderator</td>\n",
       "      <td>t5_2rm4d</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>fecu80</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>poppy_moonray</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/nosleep/comments/fecu80/january_2020_winners/</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>True</td>\n",
       "      <td>https://redd.it/fectho</td>\n",
       "      <td>13825083</td>\n",
       "      <td>1.583498e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>nosleep</td>\n",
       "      <td>**1.**\\n\\nIt was a shock when our family cat, ...</td>\n",
       "      <td>t2_4t6heh2e</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ALL EIGHTEEN LIVES OF OMEN, THE CAT</td>\n",
       "      <td>[]</td>\n",
       "      <td>r/nosleep</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_fetxdk</td>\n",
       "      <td>False</td>\n",
       "      <td>dark</td>\n",
       "      <td>None</td>\n",
       "      <td>public</td>\n",
       "      <td>2351</td>\n",
       "      <td>4</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2351</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>1.58359e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'gid_1': 2, 'gid_2': 1}</td>\n",
       "      <td>[writing]</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1.583609e+09</td>\n",
       "      <td>text</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>self.nosleep</td>\n",
       "      <td>True</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'count': 1, 'is_enabled': True, 'subreddit_i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t5_2rm4d</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>fetxdk</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>Max-Voynich</td>\n",
       "      <td>None</td>\n",
       "      <td>78</td>\n",
       "      <td>True</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/nosleep/comments/fetxdk/all_eighteen_lives_...</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/nosleep/comments/fetx...</td>\n",
       "      <td>13825083</td>\n",
       "      <td>1.583580e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  approved_at_utc subreddit  \\\n",
       "0            None   nosleep   \n",
       "1            None   nosleep   \n",
       "2            None   nosleep   \n",
       "\n",
       "                                            selftext author_fullname  saved  \\\n",
       "0                                                         t2_c446v4f  False   \n",
       "1                                                           t2_m297o  False   \n",
       "2  **1.**\\n\\nIt was a shock when our family cat, ...     t2_4t6heh2e  False   \n",
       "\n",
       "  mod_reason_title  gilded  clicked                                title  \\\n",
       "0             None       0    False    February 2020 contest nominations   \n",
       "1             None       0    False                January 2020 Winners!   \n",
       "2             None       1    False  ALL EIGHTEEN LIVES OF OMEN, THE CAT   \n",
       "\n",
       "  link_flair_richtext subreddit_name_prefixed  hidden  pwls  \\\n",
       "0                  []               r/nosleep   False     6   \n",
       "1                  []               r/nosleep   False     6   \n",
       "2                  []               r/nosleep   False     6   \n",
       "\n",
       "  link_flair_css_class  downs  hide_score       name  quarantine  \\\n",
       "0                 None      0       False  t3_fdub8s       False   \n",
       "1                 None      0       False  t3_fecu80       False   \n",
       "2                 None      0       False  t3_fetxdk       False   \n",
       "\n",
       "  link_flair_text_color author_flair_background_color subreddit_type   ups  \\\n",
       "0                  dark                          None         public    56   \n",
       "1                  dark                          None         public    54   \n",
       "2                  dark                          None         public  2351   \n",
       "\n",
       "   total_awards_received media_embed author_flair_template_id  \\\n",
       "0                      1          {}                     None   \n",
       "1                      0          {}                     None   \n",
       "2                      4          {}                     None   \n",
       "\n",
       "   is_original_content user_reports secure_media  is_reddit_media_domain  \\\n",
       "0                False           []         None                   False   \n",
       "1                False           []         None                   False   \n",
       "2                False           []         None                   False   \n",
       "\n",
       "   is_meta category secure_media_embed link_flair_text  can_mod_post  score  \\\n",
       "0    False     None                 {}            None         False     56   \n",
       "1    False     None                 {}            None         False     54   \n",
       "2    False     None                 {}            None         False   2351   \n",
       "\n",
       "  approved_by  author_premium thumbnail       edited author_flair_css_class  \\\n",
       "0        None           False                  False                   None   \n",
       "1        None           False                  False                   None   \n",
       "2        None            True            1.58359e+09                   None   \n",
       "\n",
       "  author_flair_richtext                  gildings content_categories  is_self  \\\n",
       "0                    []                        {}          [writing]    False   \n",
       "1                    []                        {}          [writing]    False   \n",
       "2                    []  {'gid_1': 2, 'gid_2': 1}          [writing]     True   \n",
       "\n",
       "  mod_note       created link_flair_type  wls removed_by_category banned_by  \\\n",
       "0     None  1.583439e+09            text    6                None      None   \n",
       "1     None  1.583527e+09            text    6                None      None   \n",
       "2     None  1.583609e+09            text    6                None      None   \n",
       "\n",
       "  author_flair_type        domain  allow_live_comments  \\\n",
       "0              text       redd.it                False   \n",
       "1              text       redd.it                 True   \n",
       "2              text  self.nosleep                 True   \n",
       "\n",
       "                                       selftext_html likes suggested_sort  \\\n",
       "0                                               None  None           None   \n",
       "1                                               None  None           None   \n",
       "2  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  None           None   \n",
       "\n",
       "  banned_at_utc view_count  archived  no_follow  is_crosspostable  pinned  \\\n",
       "0          None       None     False      False             False   False   \n",
       "1          None       None     False      False             False   False   \n",
       "2          None       None     False      False             False   False   \n",
       "\n",
       "   over_18                                      all_awardings awarders  \\\n",
       "0    False  [{'count': 1, 'is_enabled': True, 'subreddit_i...       []   \n",
       "1    False                                                 []       []   \n",
       "2    False  [{'count': 1, 'is_enabled': True, 'subreddit_i...       []   \n",
       "\n",
       "   media_only  can_gild  spoiler  locked author_flair_text  visited  \\\n",
       "0       False     False    False    True              None    False   \n",
       "1       False     False    False    True              None    False   \n",
       "2       False     False    False   False              None    False   \n",
       "\n",
       "  removed_by num_reports distinguished subreddit_id mod_reason_by  \\\n",
       "0       None        None     moderator     t5_2rm4d          None   \n",
       "1       None        None     moderator     t5_2rm4d          None   \n",
       "2       None        None          None     t5_2rm4d          None   \n",
       "\n",
       "  removal_reason link_flair_background_color      id  is_robot_indexable  \\\n",
       "0           None                              fdub8s                True   \n",
       "1           None                              fecu80                True   \n",
       "2           None                              fetxdk                True   \n",
       "\n",
       "  report_reasons         author discussion_type  num_comments  send_replies  \\\n",
       "0           None  TheCusterWolf            None             0          True   \n",
       "1           None  poppy_moonray            None             0          True   \n",
       "2           None    Max-Voynich            None            78          True   \n",
       "\n",
       "  whitelist_status  contest_mode mod_reports  author_patreon_flair  \\\n",
       "0          all_ads         False          []                 False   \n",
       "1          all_ads         False          []                 False   \n",
       "2          all_ads         False          []                 False   \n",
       "\n",
       "  author_flair_text_color                                          permalink  \\\n",
       "0                    None  /r/nosleep/comments/fdub8s/february_2020_conte...   \n",
       "1                    None   /r/nosleep/comments/fecu80/january_2020_winners/   \n",
       "2                    None  /r/nosleep/comments/fetxdk/all_eighteen_lives_...   \n",
       "\n",
       "  parent_whitelist_status  stickied  \\\n",
       "0                 all_ads      True   \n",
       "1                 all_ads      True   \n",
       "2                 all_ads     False   \n",
       "\n",
       "                                                 url  subreddit_subscribers  \\\n",
       "0                             https://redd.it/fduax3               13825083   \n",
       "1                             https://redd.it/fectho               13825083   \n",
       "2  https://www.reddit.com/r/nosleep/comments/fetx...               13825083   \n",
       "\n",
       "    created_utc  num_crossposts media  is_video link_flair_template_id  \n",
       "0  1.583410e+09               0  None     False                    NaN  \n",
       "1  1.583498e+09               0  None     False                    NaN  \n",
       "2  1.583580e+09               3  None     False                    NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the 3rd layer of dict, with key 'data' for better view\n",
    "# selftext (only has value started from 3rd row) is the post text that I would like to compile for modelling\n",
    "\n",
    "df = pd.DataFrame(p['data'] for p in nosleep_dict['data']['children'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 100)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By default, Reddit will give you the top 25 posts. (note the first 2 rows have no post)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Reddit will give you the top 25 posts .\n",
    "To get the next 25 posts, will need the name ID of the last post data, \n",
    "which is the key 'after' that I mentioned in previous few cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t3_fey7gw'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the name of the last post.\n",
    "nosleep_dict['data']['after']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Collecting post from two subreddits\n",
    "\n",
    "Below is the loop function to collect more in reddits.com\n",
    "\n",
    "However, Reddit limit the number of requests per second you're allowed to make. Thus, will need to add timer to delay the loop for each requests, using `time.sleep()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function to scrap post from Reddits.com ######\n",
    "def collect_post(url, after):\n",
    "    posts = []      # empty list to store the post after scraping\n",
    "    headers = {'User-agent': 'tamtam 8.1'}       # customer user-agent\n",
    "    \n",
    "    for i in range (40):\n",
    "        if after == None:\n",
    "            params = {}          # the first 25 posts\n",
    "        else: \n",
    "            params = {'after' : after}    # name of last ID post, this is for the next 25 post scraping\n",
    "            #print('id', params)\n",
    "        \n",
    "        res = requests.get(url, params = params, headers = headers)\n",
    "        \n",
    "        if res.status_code == 200:           # check if it is okay, status_code = 200 means okay\n",
    "            current_dict = res.json()       # if okay, use res.json() to convert the response         \n",
    "                                       # into a dictionary format and set this to a variable (current_dict)\n",
    "                \n",
    "            # store the values from key 'data' from its 'parent key':['data']['children']\n",
    "            current_post = [p['data'] for p in current_dict['data']['children']]\n",
    "            posts.extend(current_post)  #extend save the current_post (same row), instead of as list in the posts[]\n",
    "            \n",
    "            after = current_dict['data']['after']   # ID for next 25 post\n",
    "            print('last ID:', after)\n",
    "        else:\n",
    "            print('status error!', res.status_code)\n",
    "            break\n",
    "        \n",
    "        # generate a random sleep duration to look more 'natural', instead of fix timer\n",
    "        sleep_duration = random.randint(2,10)\n",
    "        #print(sleep_duration)\n",
    "        time.sleep(sleep_duration)\n",
    "    \n",
    "    # check the number of post collected\n",
    "    print('length of collected posts:', len(posts))\n",
    "    # check the unique ID\n",
    "    print('uniqueID:', len(set([p['name'] for p in posts])))\n",
    "    \n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If want to scrape post from First reddits,\n",
    "- change `to_scrape` to **True** in below cell\n",
    "- change to **False** after scrape completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scrape = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uncomment** below line to initial empty post for the FIRST scrape,\n",
    "**set to comment** by adding back the `#` after the first scrape, that is, before re-run the scrape post in the next cell. Else, it will start as empty post, instead of continuing to append the post collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posts_1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### scrape post from 1st subreddits\n",
    "if to_scrape:\n",
    "    after = None    # set to 'None' for the first loop of scraping, after that use the last row of\n",
    "                    # 'last ID:' e.g: 't3_f0nv9e' printed out from the loop function\n",
    "        \n",
    "    url_1 = 'https://www.reddit.com/r/nosleep.json'    # url for 1st subreddit to scrape\n",
    "    scrape_1 = collect_post(url_1, after)              # call collect_post function to loop and scape from reddits\n",
    "    \n",
    "    posts_1.extend(scrape_1)\n",
    "    df_1 = pd.DataFrame(posts_1)\n",
    "    df_1.drop_duplicates(subset = 'title', inplace = True)  # drop duplicated 'title'\n",
    "    df_1.to_csv('../datasets/nosleep1.csv', index = False)   #export compiled df_1 to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If want to scrape post from the 2nd subreddits\n",
    "- change `to_scrape` to **True** in below cell\n",
    "- change to **False** after scrape completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scrape = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, **Uncomment** below line to initial empty post for the 2nd subreddits scrape.\n",
    "**set to comment** by adding back the `#` after the first scrape, that is, before re-run the scrape post in the next cell. Else, it will start as empty post, instead of continuing to append the post collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posts_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### scrape post\n",
    "if to_scrape:\n",
    "    after = 't3_dsmmvk'    # set to 'None' for the first loop of scraping, after that use the last row of\n",
    "                    # 'last ID:' e.g: 't3_f0nv9e' printed out from the loop function\n",
    "        \n",
    "    url_2 = 'https://www.reddit.com/r/Thetruthishere.json'    # url for 2nd subreddit to scrape\n",
    "    scrape_2 = collect_post(url_2, after)           # call collect_post function to loop and scape from reddits\n",
    "    \n",
    "    posts_2.extend(scrape_2)\n",
    "    df_2 = pd.DataFrame(posts_2)\n",
    "    df_2.drop_duplicates(subset = 'title', inplace = True)         # drop duplicated 'title'\n",
    "    pd.DataFrame(scrape_2).to_csv('../datasets/thetrueishere1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of post collected & ensure unique post is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1996"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check the number of post collected\n",
    "len(posts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check the unique ID (name) of the post collected\n",
    "len(set([p['title'] for p in posts_1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 101)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check the length of data save to csv\n",
    "## the total row number saved in the csv file is the same as the unique ID post. \n",
    "# This is to ensure the data collected is only wit unique post.\n",
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(994, 102)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
